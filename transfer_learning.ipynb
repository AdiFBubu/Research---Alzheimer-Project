{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "human"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4483559c30c75714"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T21:33:00.062085600Z",
     "start_time": "2025-11-18T21:32:56.447371900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID_REF GSM1423780 GSM1423781 GSM1423782 GSM1423783 GSM1423784  \\\n",
      "9630  10023830425   0.080426  -0.027666   0.085496  -0.109619    0.10504   \n",
      "9631  10023815205   0.007106   0.065091   0.040479   0.079794  -0.013048   \n",
      "9632  10025912610   0.063151  -0.118265  -0.027519  -0.250529    0.05136   \n",
      "9633          Age         67         88         62         90         90   \n",
      "9634           AD        yes        yes        yes        yes        yes   \n",
      "\n",
      "     GSM1423785 GSM1423786 GSM1423787 GSM1423788  ... GSM1424237 GSM1424238  \\\n",
      "9630  -0.100777   0.017847  -0.204545  -0.042049  ...  -0.145379   -0.07866   \n",
      "9631   0.078262   -0.04752   0.058175   0.002121  ...   0.106946   0.109338   \n",
      "9632   0.089817    0.23913   0.072385  -0.058781  ...  -0.070367  -0.058349   \n",
      "9633         95         77        100         72  ...         50         72   \n",
      "9634        yes        yes        yes        yes  ...         no         no   \n",
      "\n",
      "     GSM1424239 GSM1424240 GSM1424241 GSM1424242 GSM1424243 GSM1424244  \\\n",
      "9630  -0.058293  -0.068344  -0.013146   0.012196  -0.092569  -0.040329   \n",
      "9631   0.133428   0.176923   0.072884   0.032304    0.15921   0.012171   \n",
      "9632  -0.116657  -0.112565  -0.029919     0.0163  -0.108027    0.01683   \n",
      "9633         59         55         65         52         61         60   \n",
      "9634         no         no         no         no         no         no   \n",
      "\n",
      "     GSM1424245 GSM1424246  \n",
      "9630   -0.08024  -0.087152  \n",
      "9631   0.084873   0.119203  \n",
      "9632  -0.073553  -0.136882  \n",
      "9633         55         62  \n",
      "9634         no         no  \n",
      "\n",
      "[5 rows x 468 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in your files\n",
    "csv1 = pd.read_csv('all_human_GSE33000.csv') \n",
    "csv2 = pd.read_csv('same_mouse_human_gene_mapping.csv')\n",
    "csv3 = pd.read_csv('all_human_GSE33000_metadata.csv')  # must have 'Accession', 'Age_weeks', 'AD'\n",
    "\n",
    "# Step 1: Row filtering & reordering as before\n",
    "csv1['ID_REF'] = csv1['ID_REF'].astype(str)\n",
    "csv2['gene_id_human'] = csv2['gene_id_human'].astype(str)\n",
    "ordered_genes = csv2['gene_id_human'].tolist()\n",
    "csv1_filtered = csv1[csv1['ID_REF'].isin(ordered_genes)]\n",
    "csv1_filtered = csv1_filtered.set_index('ID_REF')\n",
    "csv1_matched_order = csv1_filtered.reindex(ordered_genes).reset_index()\n",
    "\n",
    "# Step 2: Map age & AD for each sample column\n",
    "# Make sure Accession is string and matches columns\n",
    "csv3['Accession'] = csv3['Accession'].astype(str)\n",
    "age_dict = dict(zip(csv3['Accession'], csv3['Age']))\n",
    "ad_dict  = dict(zip(csv3['Accession'], csv3['AD']))\n",
    "\n",
    "# For all columns that start with GSM (samples), build age and AD rows\n",
    "sample_cols = [col for col in csv1_matched_order.columns if col.startswith('GSM')]\n",
    "\n",
    "age_row = ['Age'] + [age_dict.get(col, '') for col in sample_cols]\n",
    "ad_row  = ['AD']  + [ad_dict.get(col, '')  for col in sample_cols]\n",
    "\n",
    "# Append the rows to the DataFrame\n",
    "df_plus_rows = pd.concat([\n",
    "    csv1_matched_order,\n",
    "    pd.DataFrame([age_row, ad_row], columns=csv1_matched_order.columns)\n",
    "], ignore_index=True)\n",
    "\n",
    "# Save to file\n",
    "# df_plus_rows.to_csv('csv1_reordered_with_age_AD.tsv', sep='\\t', index=False)\n",
    "\n",
    "# Preview the result\n",
    "print(df_plus_rows.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467, 9635)\n",
      "AD\n",
      "1.0    310\n",
      "0.0    157\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# df: original DataFrame (rows = features + metadata, columns = patients)\n",
    "\n",
    "GENE_ROWS = slice(0, 9633)      # Python slice end is exclusive; row 0..9632\n",
    "AGE_ROW = 9633\n",
    "LABEL_ROW = 9634\n",
    "\n",
    "df = df_plus_rows.copy()\n",
    "\n",
    "# 1. Split components\n",
    "gene_expr = df.iloc[GENE_ROWS, :].copy()\n",
    "age_series = df.iloc[AGE_ROW, :].copy()\n",
    "label_series = df.iloc[LABEL_ROW, :].copy()\n",
    "\n",
    "# 2. Ensure numeric gene expression\n",
    "# Coerce all to numeric; invalid parse becomes NaN\n",
    "gene_expr = gene_expr.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 3. Build a new DataFrame with samples as rows\n",
    "# Transpose gene expression so rows = patients\n",
    "X_genes = gene_expr.T  # shape: n_patients x n_genes\n",
    "X_genes.columns = [f'gene_{i}' for i in range(X_genes.shape[1])]\n",
    "\n",
    "# Add age\n",
    "age = pd.to_numeric(age_series, errors='coerce')\n",
    "X_genes['age'] = age\n",
    "\n",
    "# Labels: map yes/no (adjust mapping if your dataset uses different terms)\n",
    "y = label_series.str.strip().str.lower().map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Combine\n",
    "data = X_genes.copy()\n",
    "data['AD'] = y\n",
    "\n",
    "# Drop samples with missing label or age\n",
    "data = data.dropna(subset=['AD', 'age'])\n",
    "\n",
    "print(data.shape)        # (n_patients, n_genes + 2)\n",
    "print(data['AD'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T21:33:03.436673800Z",
     "start_time": "2025-11-18T21:33:02.053794Z"
    }
   },
   "id": "4ca6a78896c760e2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Drop genes with >20% missing values\n",
    "threshold = 0.2 * data.shape[0]\n",
    "cols_to_keep = [c for c in data.columns if c.startswith('gene_') and data[c].isna().sum() <= threshold]\n",
    "cols_to_keep += ['age', 'AD']\n",
    "data = data[cols_to_keep]\n",
    "\n",
    "# Simple imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "features = [c for c in data.columns if c not in ('AD')]\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "data[features] = imputer.fit_transform(data[features])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T21:33:14.245350700Z",
     "start_time": "2025-11-18T21:33:08.930648400Z"
    }
   },
   "id": "8294e90c99496dd3"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(columns=['AD'])\n",
    "y = data['AD']\n",
    "\n",
    "X_human_train, X_human_test, y_human_train, y_human_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T21:57:09.289325500Z",
     "start_time": "2025-11-18T21:57:08.262928800Z"
    }
   },
   "id": "396d400b002dba05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "mice"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "733bcfc38e37ccab"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID_REF GSM1570253 GSM1570254 GSM1570255 GSM1570256 GSM1570257  \\\n",
      "9630  ZYG11B    6.93133    7.13554    6.99881    6.92082    6.81639   \n",
      "9631     ZYX    12.1803    12.4074    12.2972    12.1735    12.3489   \n",
      "9632    ZZZ3    6.55961    6.58151    6.71003    6.71477    6.62435   \n",
      "9633     age         32         16         32         16         72   \n",
      "9634      AD        yes        yes         no        yes         no   \n",
      "\n",
      "     GSM1570258 GSM1570259 GSM1570260 GSM1570261  ... GSM1570576 GSM1570577  \\\n",
      "9630    6.41424    7.05888     6.9318      6.808  ...    6.85327    6.84665   \n",
      "9631    11.9116     12.059    12.1774    12.2862  ...     11.622    11.9337   \n",
      "9632    6.64601    6.66812    6.57711    6.58633  ...     6.7401    6.57661   \n",
      "9633         16          8          8         72  ...         72         72   \n",
      "9634        yes         no        yes        yes  ...         no         no   \n",
      "\n",
      "     GSM1570578 GSM1570579 GSM1570580 GSM1570581 GSM1570582 GSM1570583  \\\n",
      "9630    6.96314    6.98529    6.80583    6.76744    6.77006    6.86755   \n",
      "9631    12.3959    11.8814    12.4366     12.543    12.5883    12.3699   \n",
      "9632    6.72455    6.65566     6.7011    6.70298    6.62084    6.63199   \n",
      "9633         32         72          8         16         16          8   \n",
      "9634         no        yes        yes         no        yes         no   \n",
      "\n",
      "     GSM1570584 GSM1570585  \n",
      "9630    7.03726    6.88035  \n",
      "9631    11.9483    12.2077  \n",
      "9632    6.58501    6.64339  \n",
      "9633          8         16  \n",
      "9634        yes        yes  \n",
      "\n",
      "[5 rows x 334 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in your files\n",
    "csv1 = pd.read_csv('all_mice_GSE64398.csv') \n",
    "csv2 = pd.read_csv('same_mouse_human_gene_mapping.csv')\n",
    "csv3 = pd.read_csv('all_mice_GSE64398_metadata.csv')  # must have 'Accession', 'Age_weeks', 'AD'\n",
    "\n",
    "# Step 1: Row filtering & reordering as before\n",
    "csv1['ID_REF'] = csv1['ID_REF'].astype(str)\n",
    "csv2['gene_id_mouse'] = csv2['gene_id_mouse'].astype(str)\n",
    "ordered_genes = csv2['gene_id_mouse'].tolist()\n",
    "csv1_filtered = csv1[csv1['ID_REF'].isin(ordered_genes)]\n",
    "csv1_filtered = csv1_filtered.set_index('ID_REF')\n",
    "csv1_matched_order = csv1_filtered.reindex(ordered_genes).reset_index()\n",
    "\n",
    "# Step 2: Map age & AD for each sample column\n",
    "# Make sure Accession is string and matches columns\n",
    "csv3['Accession'] = csv3['Accession'].astype(str)\n",
    "age_dict = dict(zip(csv3['Accession'], csv3['Age_weeks']))\n",
    "ad_dict  = dict(zip(csv3['Accession'], csv3['AD']))\n",
    "\n",
    "# For all columns that start with GSM (samples), build age and AD rows\n",
    "sample_cols = [col for col in csv1_matched_order.columns if col.startswith('GSM')]\n",
    "\n",
    "age_row = ['age'] + [age_dict.get(col, '') for col in sample_cols]\n",
    "ad_row  = ['AD']  + [ad_dict.get(col, '')  for col in sample_cols]\n",
    "\n",
    "# Append the rows to the DataFrame\n",
    "df_plus_rows = pd.concat([\n",
    "    csv1_matched_order,\n",
    "    pd.DataFrame([age_row, ad_row], columns=csv1_matched_order.columns)\n",
    "], ignore_index=True)\n",
    "\n",
    "# Save to file\n",
    "# df_plus_rows.to_csv('csv1_reordered_with_age_AD.tsv', sep='\\t', index=False)\n",
    "\n",
    "# Preview the result\n",
    "print(df_plus_rows.tail(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T21:33:21.628550200Z",
     "start_time": "2025-11-18T21:33:20.697508600Z"
    }
   },
   "id": "825228ada8397612"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 9635)\n",
      "AD\n",
      "1.0    219\n",
      "0.0    114\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# df: original DataFrame (rows = features + metadata, columns = patients)\n",
    "\n",
    "GENE_ROWS = slice(0, 9633)      # Python slice end is exclusive; row 0..9632\n",
    "AGE_ROW = 9633\n",
    "LABEL_ROW = 9634\n",
    "\n",
    "df = df_plus_rows.copy()\n",
    "\n",
    "# 1. Split components\n",
    "gene_expr = df.iloc[GENE_ROWS, :].copy()\n",
    "age_series = df.iloc[AGE_ROW, :].copy()\n",
    "label_series = df.iloc[LABEL_ROW, :].copy()\n",
    "\n",
    "# 2. Ensure numeric gene expression\n",
    "# Coerce all to numeric; invalid parse becomes NaN\n",
    "gene_expr = gene_expr.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 3. Build a new DataFrame with samples as rows\n",
    "# Transpose gene expression so rows = patients\n",
    "X_genes = gene_expr.T  # shape: n_patients x n_genes\n",
    "X_genes.columns = [f'gene_{i}' for i in range(X_genes.shape[1])]\n",
    "\n",
    "# Add age\n",
    "age = pd.to_numeric(age_series, errors='coerce')\n",
    "X_genes['age'] = age\n",
    "\n",
    "# Labels: map yes/no (adjust mapping if your dataset uses different terms)\n",
    "y = label_series.str.strip().str.lower().map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Combine\n",
    "data = X_genes.copy()\n",
    "data['AD'] = y\n",
    "\n",
    "# Drop samples with missing label or age\n",
    "data = data.dropna(subset=['AD', 'age'])\n",
    "\n",
    "print(data.shape)        # (n_patients, n_genes + 2)\n",
    "print(data['AD'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T21:33:32.810134900Z",
     "start_time": "2025-11-18T21:33:31.695129900Z"
    }
   },
   "id": "934739fc7973be91"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Drop genes with >20% missing values\n",
    "threshold = 0.2 * data.shape[0]\n",
    "cols_to_keep = [c for c in data.columns if c.startswith('gene_') and data[c].isna().sum() <= threshold]\n",
    "cols_to_keep += ['age', 'AD']\n",
    "data = data[cols_to_keep]\n",
    "\n",
    "# Simple imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "features = [c for c in data.columns if c not in ('AD')]\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "data[features] = imputer.fit_transform(data[features])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T21:33:44.571207Z",
     "start_time": "2025-11-18T21:33:41.245636400Z"
    }
   },
   "id": "a487e6c21b2f28a3"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(columns=['AD'])\n",
    "y = data['AD']\n",
    "\n",
    "X_mouse_train, X_mouse_test, y_mouse_train, y_mouse_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T21:57:16.190139300Z",
     "start_time": "2025-11-18T21:57:15.130967200Z"
    }
   },
   "id": "54aaef554fcbbb61"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Training label counts after downsampling:\n",
      "AD\n",
      "0.0    50\n",
      "1.0    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Downsample negatives in the training set to 100\n",
    "N_NEG_KEEP = 50\n",
    "N_POZ_KEEP = 50\n",
    "\n",
    "train_df = X_mouse_train.copy()\n",
    "train_df['AD'] = y_mouse_train\n",
    "\n",
    "neg_idx = train_df.index[train_df['AD'] == 0]\n",
    "pos_idx = train_df.index[train_df['AD'] == 1]\n",
    "print(len(pos_idx))\n",
    "\n",
    "# n_to_keep = min(N_NEG_KEEP, len(neg_idx))\n",
    "neg_keep = np.random.RandomState(42).choice(neg_idx, size=N_NEG_KEEP, replace=False)\n",
    "pos_keep = np.random.RandomState(42).choice(pos_idx, size=N_POZ_KEEP, replace=False)\n",
    "\n",
    "keep_idx = np.concatenate([pos_keep, neg_keep])\n",
    "train_df_ds = train_df.loc[keep_idx].sample(frac=1, random_state=42)  # shuffle\n",
    "\n",
    "X_mouse_train = train_df_ds.drop(columns=['AD'])\n",
    "y_mouse_train = train_df_ds['AD']\n",
    "\n",
    "print('Training label counts after downsampling:')\n",
    "print(y_mouse_train.value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T21:53:58.464167500Z",
     "start_time": "2025-11-18T21:53:58.420119900Z"
    }
   },
   "id": "2110fe18614c3cd0"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, Union, Dict, Literal\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    pd = None  # type: ignore\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "\n",
    "ArrayLike = Union[np.ndarray, \"pd.DataFrame\"]\n",
    "\n",
    "def _align_columns_if_dataframe(\n",
    "    X_source: ArrayLike, X_target: ArrayLike\n",
    ") -> Tuple[np.ndarray, np.ndarray, Optional[list]]:\n",
    "    \"\"\"\n",
    "    If inputs are pandas DataFrames, align X_target columns to X_source column order.\n",
    "    Returns numpy arrays and the aligned feature names (if DataFrames).\n",
    "    If inputs are numpy arrays, returns them unchanged and feature_names=None.\n",
    "    \"\"\"\n",
    "    if pd is not None and isinstance(X_source, pd.DataFrame) and isinstance(X_target, pd.DataFrame):\n",
    "        if set(X_source.columns) != set(X_target.columns):\n",
    "            missing_in_target = list(set(X_source.columns) - set(X_target.columns))\n",
    "            missing_in_source = list(set(X_target.columns) - set(X_source.columns))\n",
    "            raise ValueError(\n",
    "                f\"Feature mismatch between source and target.\\n\"\n",
    "                f\"Missing in target: {missing_in_target[:10]}{'...' if len(missing_in_target)>10 else ''}\\n\"\n",
    "                f\"Missing in source: {missing_in_source[:10]}{'...' if len(missing_in_source)>10 else ''}\"\n",
    "            )\n",
    "        X_target_aligned = X_target.loc[:, X_source.columns]\n",
    "        feature_names = list(X_source.columns)\n",
    "        return X_source.values, X_target_aligned.values, feature_names\n",
    "    else:\n",
    "        Xs = np.asarray(X_source)\n",
    "        Xt = np.asarray(X_target)\n",
    "        if Xs.shape[1] != Xt.shape[1]:\n",
    "            raise ValueError(f\"Feature dimension mismatch: source has {Xs.shape[1]}, target has {Xt.shape[1]}\")\n",
    "        return Xs, Xt, None\n",
    "\n",
    "def _pick_solver(penalty: str, solver: Optional[str]) -> str:\n",
    "    if solver is not None:\n",
    "        return solver\n",
    "    if penalty in (\"l1\", \"elasticnet\"):\n",
    "        return \"saga\"\n",
    "    return \"lbfgs\"\n",
    "\n",
    "def _fit_variance_threshold(\n",
    "    Xh: np.ndarray, Xm: np.ndarray, domain: Literal[\"mouse\", \"human\", \"both\"] = \"both\"\n",
    ") -> VarianceThreshold:\n",
    "    var = VarianceThreshold(threshold=0.0)\n",
    "    if domain == \"mouse\":\n",
    "        var.fit(Xm)\n",
    "    elif domain == \"human\":\n",
    "        var.fit(Xh)\n",
    "    else:\n",
    "        # Fit on stacked data so we keep features variable in either domain\n",
    "        var.fit(np.vstack([Xh, Xm]))\n",
    "    return var\n",
    "\n",
    "def _fit_scaler(\n",
    "    Xh_var: np.ndarray, Xm_var: np.ndarray, domain: Literal[\"mouse\", \"human\", \"both\"] = \"mouse\"\n",
    ") -> StandardScaler:\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    if domain == \"mouse\":\n",
    "        scaler.fit(Xm_var)\n",
    "    elif domain == \"human\":\n",
    "        scaler.fit(Xh_var)\n",
    "    else:\n",
    "        scaler.fit(np.vstack([Xh_var, Xm_var]))\n",
    "    return scaler\n",
    "\n",
    "def train_and_finetune_logreg(\n",
    "    X_human_train: ArrayLike,\n",
    "    y_human_train: np.ndarray,\n",
    "    X_mouse_train: ArrayLike,\n",
    "    y_mouse_train: np.ndarray,\n",
    "    *,\n",
    "    # Regularization\n",
    "    C_pretrain: float = 1.0,\n",
    "    C_finetune: float = 1.0,\n",
    "    penalty: str = \"l2\",\n",
    "    l1_ratio: Optional[float] = None,  # only used if penalty=\"elasticnet\"\n",
    "    solver: Optional[str] = None,      # default chosen from penalty\n",
    "    # Class weights\n",
    "    class_weight_pretrain: Optional[Union[str, dict]] = None,\n",
    "    class_weight_finetune: Optional[Union[str, dict]] = None,\n",
    "    # Preprocessing strategy\n",
    "    var_fit_domain: Literal[\"mouse\", \"human\", \"both\"] = \"both\",\n",
    "    scaler_fit_domain: Literal[\"mouse\", \"human\", \"both\"] = \"mouse\",\n",
    "    # Fine-tune mixing\n",
    "    human_weight: float = 0.0,  # 0 => mouse-only fine-tune; >0 => mix some human\n",
    "    # Optimization\n",
    "    random_state: int = 0,\n",
    "    max_iter: int = 5000,\n",
    "    tol: float = 1e-4,\n",
    "    # Control pretraining\n",
    "    pretrain_on_human: bool = True,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Pretrain on human, fine-tune on mouse. Preprocessing is fit with a target-centric strategy\n",
    "    (by default: VarianceThreshold on both domains; StandardScaler on mouse).\n",
    "    \"\"\"\n",
    "    # 1) Align features if DataFrames\n",
    "    Xh, Xm, feature_names = _align_columns_if_dataframe(X_human_train, X_mouse_train)\n",
    "\n",
    "    # 2) Preprocessing\n",
    "    var = _fit_variance_threshold(Xh, Xm, domain=var_fit_domain)\n",
    "    Xh_var = var.transform(Xh)\n",
    "    Xm_var = var.transform(Xm)\n",
    "\n",
    "    scaler = _fit_scaler(Xh_var, Xm_var, domain=scaler_fit_domain)\n",
    "    Xh_z = scaler.transform(Xh_var)\n",
    "    Xm_z = scaler.transform(Xm_var)\n",
    "\n",
    "    # 3) Build classifier\n",
    "    solver_final = _pick_solver(penalty, solver)\n",
    "    clf = LogisticRegression(\n",
    "        penalty=penalty,\n",
    "        solver=solver_final,\n",
    "        l1_ratio=l1_ratio if penalty == \"elasticnet\" else None,\n",
    "        max_iter=max_iter,\n",
    "        tol=tol,\n",
    "        random_state=random_state,\n",
    "        warm_start=True,   # we will reuse weights from pretraining\n",
    "    )\n",
    "\n",
    "    # 4) Pretrain on human (optional)\n",
    "    if pretrain_on_human:\n",
    "        clf.set_params(C=C_pretrain, class_weight=class_weight_pretrain)\n",
    "        clf.fit(Xh_z, y_human_train)\n",
    "\n",
    "    # 5) Fine-tune on mouse (optionally mix human with a small weight)\n",
    "    clf.set_params(C=C_finetune, class_weight=class_weight_finetune)\n",
    "    if human_weight > 0.0:\n",
    "        X_all = np.vstack([Xh_z, Xm_z])\n",
    "        y_all = np.concatenate([np.asarray(y_human_train), np.asarray(y_mouse_train)])\n",
    "        sw = np.concatenate([\n",
    "            np.full(len(y_human_train), float(human_weight), dtype=float),\n",
    "            np.ones(len(y_mouse_train), dtype=float)\n",
    "        ])\n",
    "        clf.fit(X_all, y_all, sample_weight=sw)\n",
    "    else:\n",
    "        clf.fit(Xm_z, y_mouse_train)\n",
    "\n",
    "    kept_mask = var.get_support()\n",
    "    kept_names = None\n",
    "    if feature_names is not None:\n",
    "        kept_names = [name for name, keep in zip(feature_names, kept_mask) if keep]\n",
    "\n",
    "    return {\n",
    "        \"var\": var,\n",
    "        \"scaler\": scaler,\n",
    "        \"clf\": clf,\n",
    "        \"feature_names\": feature_names,\n",
    "        \"kept_feature_mask\": kept_mask,\n",
    "        \"kept_feature_names\": kept_names,\n",
    "    }\n",
    "\n",
    "def transform_for_inference(preproc: Dict[str, object], X: ArrayLike) -> np.ndarray:\n",
    "    var: VarianceThreshold = preproc['var']\n",
    "    scaler: StandardScaler = preproc['scaler']\n",
    "    feature_names = preproc.get('feature_names', None)\n",
    "\n",
    "    if pd is not None and isinstance(X, pd.DataFrame) and feature_names is not None:\n",
    "        X = X.loc[:, feature_names].values\n",
    "    else:\n",
    "        X = np.asarray(X)\n",
    "    X_var = var.transform(X)\n",
    "    X_z = scaler.transform(X_var)\n",
    "    return X_z\n",
    "\n",
    "def predict_mouse(\n",
    "    preproc: Dict[str, object],\n",
    "    X_mouse: ArrayLike,\n",
    "    return_proba: bool = True\n",
    "):\n",
    "    Xz = transform_for_inference(preproc, X_mouse)\n",
    "    clf: LogisticRegression = preproc['clf']\n",
    "    y_pred = clf.predict(Xz)\n",
    "    if return_proba:\n",
    "        y_proba = clf.predict_proba(Xz)[:, 1]\n",
    "        return y_pred, y_proba\n",
    "    return y_pred\n",
    "\n",
    "def find_optimal_threshold(\n",
    "    y_true, y_proba, metric: Literal[\"balanced_accuracy\", \"f1\"] = \"balanced_accuracy\"\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Choose threshold on a validation set for either balanced accuracy or F1.\n",
    "    \"\"\"\n",
    "    thresholds = np.linspace(0.0, 1.0, 501)\n",
    "    best_thr, best_score = 0.5, -np.inf\n",
    "    for t in thresholds:\n",
    "        y_hat = (y_proba >= t).astype(int)\n",
    "        if metric == \"balanced_accuracy\":\n",
    "            score = balanced_accuracy_score(y_true, y_hat)\n",
    "        else:\n",
    "            score = f1_score(y_true, y_hat)\n",
    "        if score > best_score:\n",
    "            best_score, best_thr = score, t\n",
    "    return best_thr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T21:54:00.800833900Z",
     "start_time": "2025-11-18T21:54:00.791955300Z"
    }
   },
   "id": "e8120ab842c8369a"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.65      0.63        17\n",
      "         1.0       0.81      0.79      0.80        33\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.71      0.72      0.71        50\n",
      "weighted avg       0.74      0.74      0.74        50\n",
      "\n",
      "Accuracy: 0.74\n",
      "Balanced accuracy: 0.7174688057040999\n",
      "ROC AUC: 0.8003565062388591\n",
      "Average Precision: 0.8986798871732948\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "preproc = train_and_finetune_logreg(\n",
    "    X_human_train, y_human_train,\n",
    "    X_mouse_train, y_mouse_train,\n",
    "    # Regularization (match your baseline if needed)\n",
    "    penalty=\"l2\", solver=None,\n",
    "    C_pretrain=1.0, C_finetune=1.0,\n",
    "    class_weight_pretrain=None,\n",
    "    class_weight_finetune=None,\n",
    "    # Preprocessing strategy\n",
    "    var_fit_domain=\"both\",   # keep features variable in either domain\n",
    "    scaler_fit_domain=\"mouse\",  # scale using mouse stats\n",
    "    # Fine-tune mixing\n",
    "    human_weight=0.1,        # try {0.0, 0.05, 0.1, 0.2, 0.5}\n",
    "    random_state=0, max_iter=5000\n",
    ")\n",
    "\n",
    "# Evaluate on mouse\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, balanced_accuracy_score, average_precision_score\n",
    "y_pred, y_proba = predict_mouse(preproc, X_mouse_test)\n",
    "\n",
    "print(classification_report(y_mouse_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_mouse_test, y_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_mouse_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_mouse_test, y_proba))\n",
    "print(\"Average Precision:\", average_precision_score((np.asarray(y_mouse_test)==1).astype(int), y_proba))\n",
    "\n",
    "# Optional: threshold tuning on a mouse validation fold\n",
    "# thr = find_optimal_threshold(y_mouse_valid, y_proba_valid, metric=\"balanced_accuracy\")\n",
    "# y_pred_thr = (y_proba_test >= thr).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T21:57:21.208797900Z",
     "start_time": "2025-11-18T21:57:19.506693200Z"
    }
   },
   "id": "98b8ae89ab3b1349"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "113dc5aaedcb6f06"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
